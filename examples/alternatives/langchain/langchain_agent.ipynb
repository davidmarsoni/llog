{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a1790f",
   "metadata": {},
   "source": [
    "# LangChain Simple Agent\n",
    "\n",
    "This notebook demonstrates how to roughly use LangChain to create a simple agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a99249",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages and verify the installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain openai python-dotenv langchain_community\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    'langchain': 'LangChain',\n",
    "    'openai': 'OpenAI',\n",
    "    'dotenv': 'python-dotenv',\n",
    "    'langchain_community': 'LangChain Community'\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809b8ae",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables from the `.env` file. <br>\n",
    "N.b. it will look through the entire project for a valid `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7224d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Set environment variables for compatibility with libraries that expect them\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API keys are set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set in .env file\")\n",
    "else:\n",
    "    print(\"✅ API keys are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2abb43",
   "metadata": {},
   "source": [
    "## Build a Conversation chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09780826",
   "metadata": {},
   "source": [
    "The simplest way to use LangChain is to make a conversation chain, which you can see below is not unlike many chats available to discuss with LLMs.\n",
    "\n",
    "In this code, we will define our agent's model and then try making a conversation with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define a callable for session history\n",
    "def get_session_history_callable(session_id: str):\n",
    "    return InMemoryChatMessageHistory()\n",
    "\n",
    "# Create a conversation runnable with message history\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    runnable=llm,\n",
    "    get_session_history=get_session_history_callable\n",
    ")\n",
    "\n",
    "# Start a conversation\n",
    "try:\n",
    "    response = conversation.invoke(\n",
    "        {\"input\": \"What is a pink elephant ?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"test-session\"}}\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64bf0f5",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "Now that we have a working language model with memory, let’s take it further by building an Agent.\n",
    "\n",
    "Agents in LangChain allow the model to reason about actions and interact with tools dynamically (like a calculator, search engine, or custom function).\n",
    "\n",
    "You must first define what functionalities the agent shall have. In this case, let's make a writing agent, capable of writing different kinds of texts based on the provided prompts. This agent will have access to three different tool to help in its writing:\n",
    "\n",
    "- A `Write Blog` tool, that will create a blog post about a topic\n",
    "- A `Summarize Text` tool\n",
    "- A `Generate Title and Intro` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Write Blog\",\n",
    "        func=lambda topic: llm.invoke(f\"Write a detailed and engaging blog post about: {topic}\"),\n",
    "        description=\"Writes a blog post about the given topic.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Summarize Text\",\n",
    "        func=lambda text: llm.invoke(f\"Summarize this into bullet points:\\n\\n{text}\"),\n",
    "        description=\"Summarizes text into concise bullet points.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Generate Title and Intro\",\n",
    "        func=lambda topic: llm.invoke(f\"Create a blog post title and intro paragraph for: {topic}\"),\n",
    "        description=\"Generates a catchy title and an engaging introduction paragraph.\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor, initialize_agent\n",
    "\n",
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306ae0f",
   "metadata": {},
   "source": [
    "## Define Agent State Schema\n",
    "\n",
    "For more advanced agents, it's important to define a state schema to track the agent's state during execution.\n",
    "This helps manage the agent's memory, decisions, and outputs in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f94053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Optional\n",
    "\n",
    "# Define our state schema\n",
    "class AgentState(TypedDict):\n",
    "    # The input query from the user\n",
    "    query: str\n",
    "    # Tool choices and results\n",
    "    tool_name: Optional[str]\n",
    "    tool_input: Optional[str]\n",
    "    tool_output: Optional[str]\n",
    "    # Tracking history\n",
    "    history: List[Dict]\n",
    "    # Final output\n",
    "    final_output: Optional[str]\n",
    "\n",
    "# Example initialization of the agent state\n",
    "initial_state: AgentState = {\n",
    "    \"query\": \"\",\n",
    "    \"tool_name\": None,\n",
    "    \"tool_input\": None,\n",
    "    \"tool_output\": None,\n",
    "    \"history\": [],\n",
    "    \"final_output\": None\n",
    "}\n",
    "\n",
    "# Demonstrate how to update state during agent execution\n",
    "def update_agent_state(state: AgentState, **kwargs) -> AgentState:\n",
    "    \"\"\"Helper function to update agent state\"\"\"\n",
    "    new_state = state.copy()\n",
    "    for key, value in kwargs.items():\n",
    "        if key in new_state:\n",
    "            new_state[key] = value\n",
    "    return new_state\n",
    "\n",
    "# Example of using the state in an agent workflow\n",
    "def agent_workflow_example():\n",
    "    # Initialize state with a query\n",
    "    state = update_agent_state(initial_state, query=\"Write about apple pies\")\n",
    "    \n",
    "    # Simulate tool selection\n",
    "    state = update_agent_state(state, \n",
    "                              tool_name=\"Write Blog\",\n",
    "                              tool_input=\"evolution of apple pies\")\n",
    "    \n",
    "    # Simulate tool execution and result\n",
    "    tool_result = \"Apple pies have evolved over centuries...\"\n",
    "    state = update_agent_state(state, tool_output=tool_result)\n",
    "    \n",
    "    # Add interaction to history\n",
    "    state = update_agent_state(state, \n",
    "                              history=state[\"history\"] + [{\n",
    "                                  \"tool\": state[\"tool_name\"],\n",
    "                                  \"input\": state[\"tool_input\"],\n",
    "                                  \"output\": state[\"tool_output\"]\n",
    "                              }])\n",
    "    \n",
    "    # Set final output\n",
    "    state = update_agent_state(state, final_output=f\"Here's information about apple pies: {tool_result}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Run example workflow\n",
    "example_state = agent_workflow_example()\n",
    "print(\"Example Agent State:\")\n",
    "for key, value in example_state.items():\n",
    "    print(f\"{key}: {value if key != 'history' else len(value)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the agent and handle potential parsing errors\n",
    "try:\n",
    "    blog_post = agent.run(\n",
    "        input=\"Write a blog post about the evolution of apple pies.\",\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    print(blog_post)\n",
    "except ValueError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now, using the previous prompt, let's make another query to the agent\n",
    "try:\n",
    "    title_intro = agent.run(\n",
    "        input=\"Define the title and intro for this blog post: \" + blog_post,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    print(title_intro)\n",
    "except ValueError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now, let's use the agent to summarize the blog post we just created\n",
    "try:\n",
    "    summary = agent.run(\n",
    "        input=\"Summarize the blog post into bullet points: \" + blog_post,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    print(response)\n",
    "except ValueError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now let's assemble the blog post using the title, intro, and summary\n",
    "print(\"\\nAssembled Blog Post: \\n Title and Intro: \\n\" + title_intro + \"\\n\\n Excerpt: \\n\" + summary + \"\\n\\n Blog Post: \\n\" + blog_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
