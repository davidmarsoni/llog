{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1da718",
   "metadata": {},
   "source": [
    "# LangGraph Simple Agent\n",
    "\n",
    "This notebook demonstrates how to create a basic agent using LangGraph, focusing on LangGraph's state management and workflow capabilities that distinguish it from LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a523c",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89db2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -U langgraph langchain openai python-dotenv\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    'langgraph': 'LangGraph',\n",
    "    'openai': 'OpenAI',\n",
    "    'dotenv': 'python-dotenv',\n",
    "    'langchain': 'LangChain'\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb496076",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API keys are set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set in .env file\")\n",
    "else:\n",
    "    print(\"✅ API keys are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b943e",
   "metadata": {},
   "source": [
    "## LangGraph Basics\n",
    "\n",
    "LangGraph is a framework built on top of LangChain for creating stateful, multi-agent workflows with LLMs. Unlike basic LangChain agents, LangGraph provides:\n",
    "\n",
    "- **Explicit state management** - Track state across multiple calls\n",
    "- **Conditional workflow branching** - Send execution down different paths based on state\n",
    "- **Feedback loops** - Allow cycles in your agent workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9f1d7",
   "metadata": {},
   "source": [
    "## Initialize Language Model and Define Tools\n",
    "\n",
    "First, let's set up the language model and define the tools our agent will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df35ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define simple writing tools\n",
    "def write_blog(topic):\n",
    "    \"\"\"Write a blog post about a given topic.\"\"\"\n",
    "    response = llm.invoke(f\"Write a detailed and engaging blog post about: {topic}\")\n",
    "    return response.content\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Summarize text into bullet points.\"\"\"\n",
    "    response = llm.invoke(f\"Summarize this into bullet points:\\n\\n{text}\")\n",
    "    return response.content\n",
    "\n",
    "def generate_title(topic):\n",
    "    \"\"\"Generate a catchy title and intro for a topic.\"\"\"\n",
    "    response = llm.invoke(f\"Create a blog post title and intro paragraph for: {topic}\")\n",
    "    return response.content\n",
    "\n",
    "# Create tool objects (we'll use these in our LangGraph nodes)\n",
    "tools = {\n",
    "    \"write_blog\": write_blog,\n",
    "    \"summarize_text\": summarize_text,\n",
    "    \"generate_title\": generate_title\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfe494",
   "metadata": {},
   "source": [
    "## Define State Schema\n",
    "\n",
    "A key aspect of LangGraph is explicit state management. A schema is a structured representation of the state, defining the expected fields and their types. \n",
    "\n",
    "Let's define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define our state schema\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    tool: Optional[str]\n",
    "    result: Optional[str]\n",
    "    final_output: Optional[str]\n",
    "\n",
    "\n",
    "# Define the initial state creation function. This function will be call the whole workflow instead of the individual nodes later.\n",
    "def create_initial_state(query: str) -> AgentState:\n",
    "    \"\"\"Create the initial state for the workflow.\"\"\"\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"tool\": None,\n",
    "        \"result\": None,\n",
    "        \"final_output\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143fd323",
   "metadata": {},
   "source": [
    "## Define the Nodes\n",
    "\n",
    "LangGraph works with nodes (functions that process state). Let's define our nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool selector node\n",
    "def select_tool(state: AgentState) -> AgentState: #thanks to the state given by create_initial_state, this node will select the tool to be used.\n",
    "    \"\"\"Select a tool based on the query.\"\"\"\n",
    "    query = state[\"query\"].lower()\n",
    "    if \"summary\" in query or \"summarize\" in query:\n",
    "        selected_tool = \"summarize_text\"\n",
    "    elif \"blog\" in query in query:\n",
    "        selected_tool = \"write_blog\"\n",
    "    elif \"title\" in query:\n",
    "        selected_tool = \"generate_title\"\n",
    "    else:\n",
    "        selected_tool = \"write_blog\"  # Default tool\n",
    "    print(f\"Selected tool: {selected_tool}\")\n",
    "    return {**state, \"tool\": selected_tool}\n",
    "\n",
    "# Tool execution node\n",
    "def run_tool(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute the selected tool.\"\"\"\n",
    "    tool_name = state[\"tool\"]\n",
    "    query = state[\"query\"]\n",
    "    tool_function = tools.get(tool_name)\n",
    "    if not tool_function:\n",
    "        result = f\"Error: Tool '{tool_name}' not found.\"\n",
    "    else:\n",
    "        result = tool_function(query)\n",
    "    print(f\"Tool result: {result[:100]}...\")\n",
    "    return {**state, \"result\": result}\n",
    "\n",
    "\n",
    "# Final output node\n",
    "def format_output(state: AgentState) -> AgentState:\n",
    "    \"\"\"Format the final output and update the state.\"\"\"\n",
    "    formatted_output = f\"## Tool Used: {state['tool']}\\n\\n{state['result']}\"\n",
    "    print(f\"Formatted output: {formatted_output[:100]}...\")\n",
    "    return {**state, \"final_output\": formatted_output}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f0366",
   "metadata": {},
   "source": [
    "## Create the Workflow\n",
    "\n",
    "Now we'll assemble these nodes into a LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea17cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LangGraph Workflow (each function become a node, a step in our workflow)\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"select_tool\", select_tool)\n",
    "graph.add_node(\"run_tool\", run_tool)\n",
    "graph.add_node(\"format_output\", format_output)\n",
    "\n",
    "graph.set_entry_point(\"select_tool\")\n",
    "graph.add_edge(\"select_tool\", \"run_tool\")\n",
    "graph.add_edge(\"run_tool\", \"format_output\")\n",
    "graph.set_finish_point(\"format_output\")\n",
    "\n",
    "tool_agent = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f95797",
   "metadata": {},
   "source": [
    "## Testing the Workflow\n",
    "\n",
    "Let's run the workflow with a specific query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e647a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the workflow with a sample query\n",
    "query = \"generate a summary about the benefits of drinking water\"\n",
    "print(f\"Running workflow for query: \\\"{query}\\\"\")\n",
    "initial_state = create_initial_state(query) # Create the initial state, this will be the input for the workflow\n",
    "result = tool_agent.invoke(initial_state) # Execute the workflow with the initial state\n",
    "\n",
    "# Display the results\n",
    "\n",
    "print(\"====WORKFLOW RESULTS====\")\n",
    "print(f\"\\nQuery: {result['query']}\")\n",
    "print(f\"\\nSelected Tool: {result['tool']}\")\n",
    "print(f\"\\nFinal Output:\\n{result['final_output']}\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3528d4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to build a simple agent using LangGraph's distinctive features:\n",
    "\n",
    "1. **State Management** - Using TypedDict for structured state control\n",
    "2. **Node-Based Processing** - Individual functions that transform state\n",
    "3. **Explicit Workflows** - Clear definition of how nodes connect\n",
    "\n",
    "Key differences from LangChain agents:\n",
    "- LangGraph provides explicit state management between steps\n",
    "- Workflows are defined as graphs with clear execution paths\n",
    "- Each node is responsible for handling and updating specific parts of the state\n",
    "\n",
    "This simple example shows the core concepts of LangGraph; in more complex scenarios, you could extend this with conditional branching and feedback loops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
